{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a78aa5a",
   "metadata": {},
   "source": [
    "# Fake News Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ae378",
   "metadata": {},
   "source": [
    "### All libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03741de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m \u001b[38;5;66;03m#for data cleaning purpose\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m \u001b[38;5;66;03m#to deal with text data\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m#for visualizing dataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd #for importing dataset\n",
    "import numpy as nm #for doing mathematical operations \n",
    "from sklearn.model_selection import train_test_split as ttp #to break dataset for training and testing\n",
    "from sklearn.metrics import classification_report # to generate classification report\n",
    "import re #for data cleaning purpose\n",
    "import string #to deal with text data\n",
    "import matplotlib.pyplot as plt #for visualizing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6caab",
   "metadata": {},
   "source": [
    "### Read Two Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b391227c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (274628442.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    data_true=pd.read_csv(\"C:\\Users\\admin\\Desktop\\Fake news detection\\True.csv\")\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "data_true=pd.read_csv(\"C:\\Users\\admin\\Desktop\\Fake news detection\\True.csv\")\n",
    "data_fake=pd.read_csv(\"C:\\Users\\admin\\Desktop\\Fake news detection\\Fake.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd3978",
   "metadata": {},
   "source": [
    "### Display both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53090598",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_true\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_true' is not defined"
     ]
    }
   ],
   "source": [
    "data_true.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b413b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541d719",
   "metadata": {},
   "source": [
    "### Add Column Name In Both Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916c8bca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_true\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m data_fake[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_true' is not defined"
     ]
    }
   ],
   "source": [
    "data_true[\"class\"] = 1\n",
    "data_fake[\"class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96112658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a61c4",
   "metadata": {},
   "source": [
    "### Taking last 10 values for manual testing from both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f20c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true_manual_testing = data_true.tail(10)\n",
    "for i in range(21416,21406,-1):\n",
    "    data_true.drop([i],axis=0, inplace=True)#removing those 10 values from original dataset\n",
    "    \n",
    "data_fake_manual_testing = data_fake.tail(10)\n",
    "for i in range(21416,21406,-1):\n",
    "    data_fake.drop([i],axis=0, inplace=True)#removing those 10 values from original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b8d10",
   "metadata": {},
   "source": [
    "### merging these two datasets in single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manual_testing = pd.concat([data_fake_manual_testing, data_true_manual_testing], axis=0)\n",
    "data_manual_testing.to_csv(\"manual_testing.csv \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8086ac",
   "metadata": {},
   "source": [
    "### Merging main two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = pd.concat([data_fake,data_true],axis=0)\n",
    "data_merge.head(10)#displaying first 10 values after above operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32a96f",
   "metadata": {},
   "source": [
    "### Performing some basic data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7406da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_merge.groupby(['subject'])['text'].count())\n",
    "data_merge.groupby(['subject'])['text'].count().plot(kind=\"bar\")\n",
    "plt.title(\"Articles per subject\",size=20)\n",
    "plt.xlabel(\"Category\",size=20)\n",
    "plt.ylabel(\"Article count\",size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ae231",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_merge.groupby(['class'])['text'].count())\n",
    "print(\"0 = Fake news\\n1 = True news\")\n",
    "data_merge.groupby(['class'])['text'].count().plot(kind=\"pie\")\n",
    "plt.title(\"Fake news and True News\",size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2ea15",
   "metadata": {},
   "source": [
    "### Removing 3 columns from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5869c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_merge.drop([\"title\",\"subject\",\"date\"], axis=1)\n",
    "data.head(10) #displaying remaining dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26cc6a",
   "metadata": {},
   "source": [
    "### Shuffling the dataset for better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(frac=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d67d4",
   "metadata": {},
   "source": [
    "### Checking  null values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d8dc2",
   "metadata": {},
   "source": [
    "### Creating data filtering function to remove unwanted data from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(data):\n",
    "    text=data.lower()\n",
    "    text=re.sub(r'\\[.*?\\]','',text)\n",
    "    text=re.sub(r\"\\\\W\",\" \",text)\n",
    "    text=re.sub(r'https?://\\s+|www\\.S+','',text)\n",
    "    text=re.sub(r'<.*?>+','',text)\n",
    "    text=re.sub(r'[%s]'% re.escape(string.punctuation),'',text)\n",
    "    text=re.sub(r'\\w*\\d\\w*','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19f25e",
   "metadata": {},
   "source": [
    "### Filtering data of our text column using above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"]= data[\"text\"].apply(filtering)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a9e62",
   "metadata": {},
   "source": [
    "### Creating Dependant and independant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7737bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[\"text\"]\n",
    "y=data[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ee8d3",
   "metadata": {},
   "source": [
    "### Spliting dataset for training and testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e882b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=ttp(x,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe21f74",
   "metadata": {},
   "source": [
    "## Vectorizing the text\n",
    "### The sklearn. feature_extraction module is used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b14d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer() # creating object \n",
    "#Learn vocabulary and IDF(inverse document frequency), return document-term matrix. \n",
    "#IDF returns numerical statics that how the word is important to the document\n",
    "xv_train=vector.fit_transform(x_train)\n",
    "xv_test=vector.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d3533",
   "metadata": {},
   "source": [
    "## Classifaction using various classifers\n",
    "## Logistic Regression\n",
    "### Calculating probability of event occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18092032",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression()\n",
    "LR.fit(xv_train,y_train) #training or fitting the model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(LR.score(xv_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be2e7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0813f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_LR= LR.predict(xv_test) # Predict using the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372421b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_LR)) #creating classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc68a2c",
   "metadata": {},
   "source": [
    "## Creating confusion matrix\n",
    "### determine the performance of the classification models for a given set of test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f965cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "cm= confusion_matrix(y_test,pred_LR)  \n",
    "print(cm)\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,cmap=\"BuPu\",annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6a53b",
   "metadata": {},
   "source": [
    "## Decision Tree Classification\n",
    "### Non-parametric supervised learning method used for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c79d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(xv_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(DT.score(xv_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_DT = DT.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= confusion_matrix(y_test,pred_DT)  \n",
    "print(cm)\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,cmap=\"PiYG\",annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79f9d4",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "### Supervised Machine learning algorithm used for classification, regression, and other tasks using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0457c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(random_state=0)\n",
    "RFC.fit(xv_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC.score(xv_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_RFC = RFC.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cef1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_RFC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c17bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= confusion_matrix(y_test,pred_RFC)  \n",
    "print(cm)\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,cmap=\"Blues\",annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce77b7c",
   "metadata": {},
   "source": [
    "## Manual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2454a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_lable(n):\n",
    "    if n == 0:\n",
    "        return \"FAKE News\"\n",
    "    elif n == 1:\n",
    "        return \"TRUE News\"\n",
    "    \n",
    "def manual_testing(news):\n",
    "    testing_news = {\"text\":[news]}\n",
    "    new_def_test = pd.DataFrame(testing_news)\n",
    "    new_def_test[\"text\"] = new_def_test[\"text\"].apply(filtering) \n",
    "    new_x_test = new_def_test[\"text\"]\n",
    "    new_xv_test = vector.transform(new_x_test)\n",
    "    pred_LR = LR.predict(new_xv_test)\n",
    "    pred_DT = DT.predict(new_xv_test)\n",
    "    \n",
    "    pred_RFC = RFC.predict(new_xv_test)\n",
    "\n",
    "    return print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nRFC Prediction: {}\".format(output_lable(pred_LR[0]),\n",
    "                                                                                                              output_lable(pred_DT[0]), \n",
    "                                                                                                               \n",
    "                                                                                                              output_lable(pred_RFC[0]))) \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa7c7a",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49cf9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = str(input())\n",
    "manual_testing(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = str(input())\n",
    "manual_testing(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182d36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
